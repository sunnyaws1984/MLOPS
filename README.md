# MLOPS
Sample House Predictions using Machine Learning

Below are the steps to perform:

1) Setup a Virtual env.
2) pip install pandas numpy scikit-learn gradio mlflow
3) python model.py

Youâ€™ll get a web UI like:

Living Area: 2000
Basement: 900
Quality: 7
Year Built: 2005
â†’ Predicted Price: 236,889

################################################################################################################################

ğŸ“ What is Linear Regression?

Linear Regression is a machine learning algorithm that predicts a numeric value by learning a straight-line relationship between input features and the target.

ğŸ“Œ In simple words

It uses a single formula to predict outputs:

Price = (w1 Ã— Feature1) + (w2 Ã— Feature2) + â€¦ + b
The model learns weights (w1, w2, â€¦) and a base (b) from the training data
eg:
Price =
  (a Ã— GrLivArea)
+ (b Ã— TotalBsmtSF)
+ (c Ã— OverallQual)
+ (d Ã— YearBuilt)
+ base price

Each feature contributes proportionally to the prediction
Predictions are a linear combination of features
Works best when the relationship between inputs and output is roughly straight-line


ğŸŒ³ What is Random Forest?

Random Forest is a machine learning algorithm that makes predictions by building many decision trees and combining their results.

ğŸ“Œ In simple words

It does not use a single rule or formula
It creates many decision trees, each trained slightly differently
Every tree gives its own prediction
The final answer is the average of all trees (for regression)
Each tree learns different patterns from the data

Eg:
Build Tree 1 â†’ makes a prediction
Build Tree 2 â†’ makes a prediction
â€¦ up to Tree 100

Final prediction = average of all 100 tree predictions

ğŸ”¹ Key Differences
 	                Linear Regression	                                            Random Forest
Formula    	      Uses a single straight-line formula (weights + base)	      Uses many decision trees and averages their predictions
Relationship	  Assumes a linear relationship between features and target	  Can capture complex, non-linear relationships
Interpretability  Very easy to explain (weights show feature importance)	  Harder to explain (rules inside many trees)
Accuracy	      Works well for simple, linear problems	                  Usually more accurate for complex data
Training	      Fast	                                                      Slower (many trees to train)
Prediction Style  Direct calculation using formula	                          Voting / averaging across trees
